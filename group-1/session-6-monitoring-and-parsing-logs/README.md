---
layout:
  width: wide
  title:
    visible: true
  description:
    visible: false
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
  metadata:
    visible: true
---

# Session 6: Monitoring and parsing logs

<figure><img src="../../.gitbook/assets/sess66-ezgif.webp" alt=""><figcaption></figcaption></figure>

Monitoring and parsing logs is one of the most essential security engineering practices in any production environment.

This unit explores how logs are generated, formatted, collected, and analyzed across various layers of the infrastructure stack, from applications to operating systems to networks.

Students will gain an operational understanding of how to identify log sources, use modern tools for log aggregation and search (such as Loki), and develop awareness of log structure, integrity, and retention requirements.

***

## ğŸ¯ Learning Objectives

By the end of Unit 6, students will:

{% hint style="info" %}
**Five Core Competencies**

1. ğŸ“š **Understand** the different types of logs and their role in system and security monitoring
2. ğŸ” **Identify** log structures (e.g., RFC 3164, RFC 5424, `journald`) and apply appropriate parsing techniques
3. ğŸ”§ **Explore and configure** log aggregation pipelines using modern tools like Grafana Loki
4. ğŸ¯ **Analyze** real-world security events using log data and query languages
5. ğŸ”’ **Learn** how log immutability and integrity contribute to reliable forensics and compliance
{% endhint %}

<details>

<summary>ğŸ“‹ Detailed Breakdown: What Each Objective Covers</summary>

**1. Log Types & Monitoring Roles**

* Application logs, system logs, security logs, audit logs
* When each type matters for investigations

**2. Log Structures & Parsing**

* RFC 3164 (BSD syslog), RFC 5424 (modern syslog), journald binary format
* Parsing techniques for structured and unstructured logs

**3. Log Aggregation Pipelines**

* Grafana Loki architecture and configuration
* Collection, transformation, and storage workflows

**4. Security Event Analysis**

* Query languages (LogQL)
* Event correlation across multiple sources

**5. Immutability & Integrity**

* Cryptographic signing and write-once storage
* Forensic reliability and compliance requirements

</details>

***

## ğŸ” Relevance & Context

{% columns %}
{% column width="60%" %}
{% hint style="success" %}
**ğŸ–ï¸ The First Source of Truth**

Logs are often the first and best source of truth when diagnosing an incident, auditing a system, or responding to a breach.
{% endhint %}

Without well-structured, searchable, and preserved logs, response teams are blind to what actually happened.

**This unit trains students to think like operators and defenders** â€” ensuring logs serve their critical role in security operations.
{% endcolumn %}

{% column %}
{% hint style="warning" %}
**âš ï¸ Critical Reality**

Attackers know logs tell the story. That's why **log tampering** is a common post-compromise activity.

Defense requires logs that are **complete, available, immutable, and actionable**.
{% endhint %}
{% endcolumn %}
{% endcolumns %}

***

### ğŸ¯ The Four Pillars of Effective Logging

<table data-card-size="large" data-view="cards"><thead><tr><th></th><th></th><th data-hidden data-card-target data-type="content-ref"></th></tr></thead><tbody><tr><td><strong>ğŸ“ Complete Coverage</strong></td><td>All relevant events are captured â€” no blind spots. Every layer of the stack generates logs.</td><td></td></tr><tr><td><strong>ğŸ” Always Available</strong></td><td>Accessible when needed for investigation. Centralized, indexed, and queryable in real-time.</td><td></td></tr><tr><td><strong>ğŸ”’ Tamper-Proof</strong></td><td>Cannot be altered or deleted. Write-once storage with cryptographic integrity verification.</td><td></td></tr><tr><td><strong>âš¡ Ready for Action</strong></td><td>Structured for rapid analysis and alerting. Query-optimized with proper labeling and indexing.</td><td></td></tr></tbody></table>

***

{% hint style="info" %}
**ğŸ”— Building on Previous Learning**

This unit builds directly on previous units around compliance and auditing, preparing learners to create scalable observability strategies that support both security and performance goals.

**Logs are the foundation** of security monitoring, compliance validation, and operational visibility.
{% endhint %}

***

## ğŸ’¡ Key Concepts I'll Learn

### ğŸ“Š Log Sources Across the Infrastructure Stack

{% tabs %}
{% tab title="ğŸ–¥ï¸ Application Logs" %}
**Events generated by software applications**

**What They Capture:**

* Errors and exceptions
* User actions and transactions
* API calls and responses
* Business logic events

**Format & Collection:**

* JSON, plain text, custom formats
* Written to files or stdout/stderr
* Critical for debugging and security

{% hint style="info" %}
Application logs provide **business context** that system logs cannot â€” they tell you _what users did_, not just _what the system did_.
{% endhint %}
{% endtab %}

{% tab title="âš™ï¸ System Logs" %}
**Operating system events managed by journald or syslog**

**What They Capture:**

* Service starts and stops
* Kernel messages
* Authentication events
* Resource utilization

**Format & Collection:**

* Journald binary format
* RFC 5424 syslog
* Structured metadata (timestamps, PIDs)
* Direct journald API access

{% hint style="info" %}
System logs provide the **operational foundation** â€” understanding what the OS is doing is essential for debugging application issues.
{% endhint %}
{% endtab %}

{% tab title="ğŸ” Security & Audit Logs" %}
**Security-focused event logging**

**What They Capture:**

* Failed login attempts
* Privilege escalations
* File access events
* Firewall blocks
* Policy violations

**Format & Collection:**

* Audit log format (auditd)
* Structured security events
* SELinux denials
* Often require special handling

{% hint style="danger" %}
**High-Value Target**: Security logs are prime targets for attackers. They must be protected with **immutability controls** and **remote collection**.
{% endhint %}
{% endtab %}

{% tab title="ğŸŒ Network Logs" %}
**Traffic, connections, and protocol-level events**

**What They Capture:**

* Firewall accept/deny decisions
* DNS queries and responses
* HTTP/HTTPS requests
* Network flows (NetFlow)
* Packet captures

**Format & Collection:**

* Syslog from network devices
* NetFlow/IPFIX formats
* PCAP for packet-level
* Often the largest log volume

{% hint style="info" %}
Network logs reveal **lateral movement** and **data exfiltration** â€” critical for detecting advanced attackers who've compromised individual hosts.
{% endhint %}
{% endtab %}
{% endtabs %}

***

### ğŸ“ Understanding Log Format Evolution

{% columns %}
{% column width="50%" %}
**ğŸ“œ Legacy: RFC 3164 (BSD Syslog)**

```
<34>Oct 11 22:14:15 myhost app[1234]: Connection failed
```

{% hint style="warning" %}
**Challenges:**

* Unstructured message field
* Ambiguous parsing (regex required)
* Limited metadata
* No standardization beyond basics
{% endhint %}

**Best for:** Legacy systems, simple logging needs
{% endcolumn %}

{% column %}
**âš¡ Modern: RFC 5424**

```
<165>1 2024-10-11T22:14:15Z myhost app 1234 ID47 [meta ip="10.0.0.1"] Connection failed
```

{% hint style="success" %}
**Advantages:**

* Structured data fields
* Rich metadata (app, PID, msgid)
* Consistent parsing
* Machine-parseable by design
{% endhint %}

**Best for:** Modern infrastructure, automated analysis
{% endcolumn %}
{% endcolumns %}

***

<details>

<summary>ğŸ”¬ Deep Dive: Why Structured Logging Matters</summary>

#### The Parsing Problem

**Legacy logs require regex patterns:**

```bash
grep "failed login.*user:\s*(\w+)" /var/log/auth.log
```

* Brittle â€” breaks when format changes
* Slow â€” must scan entire message
* Error-prone â€” edge cases missed

**Structured logs enable field extraction:**

```bash
{
  "timestamp": "2024-10-11T22:14:15Z",
  "event": "auth_failure",
  "user": "bob",
  "source_ip": "10.0.0.5"
}
```

* Reliable â€” fields are defined
* Fast â€” direct field access
* Complete â€” no parsing ambiguity

</details>

***

### ğŸ—ï¸ Centralized Log Aggregation Architecture

{% hint style="success" %}
**Why Centralization Is Non-Negotiable**

Modern infrastructure generates logs across dozens to hundreds of nodes. Without centralization, correlation is impossible and investigations become manual archaeology.
{% endhint %}

{% stepper %}
{% step %}
#### The Distributed Challenge

* Logs scattered across many systems
* No unified search capability
* Manual correlation required
* Logs vulnerable to local tampering
{% endstep %}

{% step %}
#### Grafana Loki: The Solution

**Design Philosophy:** Index metadata (labels), not content

**Components:**

* **Promtail** â€” Log collection agents
* **Distributors** â€” Receive and validate
* **Ingesters** â€” Buffer and chunk
* **Queriers** â€” Execute LogQL searches

**Benefits:**

* S3-compatible storage
* Cost-effective at scale
* Fast label-based queries
* Cloud-native architecture
{% endstep %}

{% step %}
#### Query Performance

| Query Type      | Performance | Use Case                     |
| --------------- | ----------- | ---------------------------- |
| Label filtering | âš¡ Fast      | Filter by host, service, env |
| Content search  | ğŸŒ Slower   | Search within log messages   |
| Regex patterns  | ğŸ¢ Slowest  | Complex pattern matching     |

{% hint style="info" %}
**Optimization Strategy:** Use labels for coarse filtering, then content search within smaller result sets.
{% endhint %}
{% endstep %}
{% endstepper %}

***

### ğŸ” Log Integrity: The Forensic Requirement

{% columns %}
{% column %}
{% hint style="danger" %}
**Critical Principle**

Logs without integrity controls are **inadmissible as evidence**. Tampered logs create false confidence while obscuring reality.
{% endhint %}
{% endcolumn %}

{% column %}
{% hint style="success" %}
**The Standard**

**Write-Once, Read-Many (WORM)**

Once written, logs cannot be modified or deleted. This is the foundation of trustworthy logging.
{% endhint %}
{% endcolumn %}
{% endcolumns %}

***

#### ğŸ›¡ï¸ Implementation Requirements

<table data-card-size="large" data-view="cards"><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><strong>ğŸ”’ Write-Once Storage</strong></td><td>Filesystem immutability flags, WORM storage devices, append-only file systems</td></tr><tr><td><strong>ğŸ” Cryptographic Signing</strong></td><td>Hash chains or digital signatures detect any tampering attempts</td></tr><tr><td><strong>ğŸ“‹ Chain of Custody</strong></td><td>Document log collection, transport, storage, and access for legal proceedings</td></tr><tr><td><strong>ğŸš« Access Controls</strong></td><td>Principle of least privilege â€” only authorized personnel can access logs</td></tr></tbody></table>

***

#### ğŸ“œ Compliance Framework Requirements

| Framework          | Key Requirement                                                   |
| ------------------ | ----------------------------------------------------------------- |
| ğŸ›¡ï¸ **STIG**       | Tamper-evident audit records, minimum 1-year retention            |
| ğŸ“˜ **NIST 800-53** | AU-9: Protection of audit information from unauthorized changes   |
| ğŸ’³ **PCI DSS**     | Requirement 10: Track and monitor all access to network resources |
| âœ… **SOC 2**        | CC7.2: System monitoring for anomalies and security events        |

***

### â³ Log Retention Strategy: Hot, Warm, Cold

{% tabs %}
{% tab title="ğŸ”¥ Hot Storage" %}
**Recent logs: 1-30 days**

**Characteristics:**

* Immediate access required
* High-speed storage (SSD/NVMe)
* Active investigation support
* Real-time query capability

**Use Cases:**

* Active incident response
* Real-time security monitoring
* Operational troubleshooting
* Performance analysis

**Cost:** Highest $/GB but essential for operations
{% endtab %}

{% tab title="ğŸŒ¡ï¸ Warm Storage" %}
**Recent months: 30-180 days**

**Characteristics:**

* Slower retrieval acceptable
* Cost-optimized storage
* Compliance queries
* Historical analysis

**Use Cases:**

* Compliance audits
* Trend analysis
* Historical investigations
* Retrospective searches

**Cost:** Moderate $/GB, balanced performance
{% endtab %}

{% tab title="â„ï¸ Cold Storage" %}
**Long-term: 6 months to 7 years**

**Characteristics:**

* Archival systems
* Glacier/tape acceptable
* Rare access expected
* Maximum cost efficiency

**Use Cases:**

* Regulatory compliance
* Legal discovery
* Long-term retention
* Forensic archives

**Cost:** Lowest $/GB but slow retrieval
{% endtab %}
{% endtabs %}

{% hint style="info" %}
**Retention Strategy Balance**

The goal is to meet compliance requirements while minimizing storage costs. Automated lifecycle policies move logs through hot â†’ warm â†’ cold storage tiers based on age.
{% endhint %}

***

## ğŸ“š Prerequisites

Before beginning Unit 6, students should:

{% columns %}
{% column %}
{% hint style="info" %}
**ğŸ”§ Technical Skills Required**

* **Command-line proficiency** with `journalctl`, `grep`, `less`, and related log inspection tools
* **System service management** using `systemctl` for service control
* **Configuration file literacy** in YAML and JSON formats
* **Basic understanding** of syslog, log rotation, and stdin/stdout concepts
{% endhint %}
{% endcolumn %}

{% column %}
{% hint style="warning" %}
**ğŸ¯ Preparation Checklist**

* [ ] Linux system access (VM or container)
* [ ] STIG Viewer 2.18 downloaded
* [ ] Comfortable with text editors (vim/nano)
* [ ] Basic networking knowledge
* [ ] Familiarity with regex patterns

**This unit is hands-on intensive** â€” theoretical knowledge alone is insufficient.
{% endhint %}
{% endcolumn %}
{% endcolumns %}

***

